{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "# An r-adaptive finite element method using neural networks for parametric self-adjoint elliptic problems\n",
    "# Author: Danilo Aballay, Federico Fuentes, Vicente Iligaray, Ángel J. Omella,\n",
    "#         David Pardo, Manuel A. Sánchez, Ignacio Tapia, Carlos Uriarte\n",
    "#########################################################################################################\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit\n",
    "import jax\n",
    "import jax.nn as nn\n",
    "import numpy as np\n",
    "from jax.example_libraries import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from fem_system import solve_and_loss, solve, solve_and_loss_scipy\n",
    "\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"1\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "import keras\n",
    "\n",
    "# Set the random seed\n",
    "keras.utils.set_random_seed(1234)\n",
    "\n",
    "dtype='float64' # double precision set to default in the SCR functions\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "keras.backend.set_floatx(dtype)\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "key = jax.random.PRNGKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset       = jnp.array(pd.read_csv('Dataset/dataset.csv').alpha)\n",
    "train_indices = jnp.array(pd.read_csv('Dataset/train_indices.csv').train_indices)\n",
    "test_indices  = jnp.array(pd.read_csv('Dataset/test_indices.csv').test_indices)\n",
    "\n",
    "train_data   = dataset[train_indices]\n",
    "test_data    = dataset[test_indices]\n",
    "subset_test  = jnp.array(pd.read_csv('Dataset/test_subset.csv').test_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ritz with uniform grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exact_Ritz(alpha):\n",
    "    alpha = jnp.asarray(alpha, dtype=jnp.float64)\n",
    "    num     = (1.5 * alpha**2 - alpha)\n",
    "    integral_term = num / (2 * alpha - 1)\n",
    "    return integral_term - alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of nodes\n",
    "n_nodes       = 16\n",
    "uniform_grid  = jnp.linspace(0, 1, n_nodes + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el ritz con grilla uniforme para el set de entrenamiento\n",
    "ritz_dict_train = {str(a): solve_and_loss(uniform_grid, a) for a in np.concatenate((train_data, subset_test))}\n",
    "\n",
    "# Calcular el ritz con grilla uniforme para el set de validación\n",
    "ritz_dict_test = {str(a): solve_and_loss(uniform_grid, a) for a in test_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network parameters\n",
    "\n",
    "def init_params(layers, key):\n",
    "    Ws = []\n",
    "    bs = []\n",
    "    for i in range(len(layers) - 1):\n",
    "        std_lecun = jnp.sqrt(1 / layers[i])\n",
    "        key, subkey = random.split(key)\n",
    "        Ws.append(random.normal(subkey, (layers[i], layers[i + 1])) * std_lecun)\n",
    "        bs.append(jnp.zeros(layers[i + 1]))\n",
    "    return [Ws, bs]\n",
    "\n",
    "@jit\n",
    "def forward_pass(A_t, params):\n",
    "    Ws, bs = params\n",
    "    H = A_t\n",
    "    for i in range(len(Ws) - 1):\n",
    "        H = jnp.matmul(H, Ws[i]) + bs[i]\n",
    "        H = jnp.tanh(H)\n",
    "    theta = nn.softmax(jnp.matmul(H, Ws[-1]) + bs[-1], axis = -1)\n",
    "    nodes = jnp.cumsum(theta, axis = -1)\n",
    "    return jnp.insert(nodes, 0, 0, axis = -1)\n",
    "\n",
    "def loss(params, alphas):\n",
    "    losses = solve_and_loss_scipy(forward_pass(alphas, params), alphas.squeeze())\n",
    "    return jnp.array([losses[i] / abs(ritz_dict_train[str(alpha)]) for i, alpha in enumerate(alphas.flatten())]).mean()\n",
    "\n",
    "def loss_test(params, alphas, J_u):\n",
    "    # Export history error\n",
    "    J_u_theta = solve_and_loss_scipy(forward_pass(alphas, params), alphas.squeeze())\n",
    "    return jnp.mean(jnp.sqrt(np.abs((J_u - J_u_theta)/J_u)))\n",
    "\n",
    "def FEM_sol(params, alpha):\n",
    "    nodes = forward_pass(alpha, params)\n",
    "    return solve(nodes, jnp.squeeze(alpha))\n",
    "\n",
    "def train(loss_fn, opt_state, alphas, test_subset, n_epochs=10, n_iter_per_epoch=1000, batch_size=1, lr=1e-2):\n",
    "    train_loss = []\n",
    "    test_loss  = []\n",
    "    J_u        = jnp.array([Exact_Ritz(i) for i in test_subset]).squeeze()\n",
    "    key = random.PRNGKey(100)\n",
    "    n_alphas = alphas.shape[0]\n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    params   = get_params(opt_state)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        key, subkey = random.split(key)\n",
    "        idx = random.choice(subkey, n_alphas, (batch_size,), replace=False)\n",
    "        sigma_batch = alphas[idx].reshape(-1, 1)\n",
    "\n",
    "        for it in range(n_iter_per_epoch):\n",
    "            params    = get_params(opt_state)\n",
    "            grads     = grad(loss_fn)(params, sigma_batch)\n",
    "            opt_state = opt_update(0, grads, opt_state)\n",
    "        \n",
    "        \n",
    "        params = get_params(opt_state)\n",
    "        loss_val = loss_fn(params, sigma_batch)\n",
    "        train_loss.append(loss_val)\n",
    "        test_loss.append(loss_test(params, test_subset, J_u))\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss: {loss_val:.4e}, Test loss: {test_loss[-1]:.4e}, lr: {lr:.4e}\")\n",
    "\n",
    "    return get_params(opt_state), opt_state, train_loss, test_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters and training configuration\n",
    "iter       = 1  # Number of iterations per epoch\n",
    "epochs     = 100\n",
    "lr         = 1e-2\n",
    "batch_size = 10\n",
    "\n",
    "# Configuración de la red neuronal\n",
    "layers = [1, 10, 10, n_nodes]\n",
    "key    = random.PRNGKey(42)\n",
    "\n",
    "# Configurar el optimizador Adam\n",
    "opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "params    = init_params(layers, key)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "# Entrenamiento\n",
    "trained_param, opt_state_save, trained_error, test_loss = train(loss, opt_state, jnp.array(train_data), jnp.array([subset_test]).T, epochs, iter, batch_size, lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(8, 5))\n",
    "axs.plot(test_loss, color='blue')\n",
    "axs.set_xlabel('Iteration')\n",
    "axs.set_ylabel('Relative Error')\n",
    "axs.set_xscale('log')\n",
    "axs.set_yscale('log')\n",
    "axs.set_title('Monitoring Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "special_test = np.array(pd.read_csv('Dataset/special_test.csv').values)\n",
    "\n",
    "# Compare the results of using the initial neural network and the final neural network\n",
    "x_exact = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 5), dpi=300)\n",
    "\n",
    "\n",
    "for i in range(len(special_test)):\n",
    "    nodes_fullNN, u_fullNN = FEM_sol(trained_param, special_test[i])\n",
    "    \n",
    "    ritz_fullNN = solve_and_loss(forward_pass(special_test[i], trained_param), special_test[i][0])\n",
    "    exact_ritz_val = Exact_Ritz(np.array(special_test[i][0]))\n",
    "    u_exact = x_exact ** special_test[i]\n",
    "    \n",
    "    ax = axs[i]\n",
    "    ax.plot(x_exact, u_exact, 'k', label=f'Exact Ritz = {Exact_Ritz(np.array(special_test[i][0])):.4f}')\n",
    "    ax.plot(nodes_fullNN, u_fullNN, 'o', color='b')\n",
    "\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('u')\n",
    "    ax.legend([f'Exact Ritz = {exact_ritz_val:.4f}', \n",
    "               f'Ritz NN param = {ritz_fullNN:.4f}',]) \n",
    "    ax.set_title(rf'Comparison using $\\alpha$ = {special_test[i][0]:.4f}')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the NN in every test data and then compare the loss with the exact Ritz value\n",
    "\n",
    "# List to save the Ritz values\n",
    "ritz_test        = []\n",
    "exact_ritz_test  = []\n",
    "error_test       = []\n",
    "rel_error_test   = []\n",
    "rel_uniform_test = []\n",
    "\n",
    "# Evaluate the NN in every test data\n",
    "for i in range(len(test_data)):\n",
    "    \n",
    "    # Calculate the Ritz value\n",
    "    ritz = solve_and_loss(forward_pass(np.array([test_data[i]]), trained_param), test_data[i])\n",
    "    ritz_test.append(ritz)\n",
    "    \n",
    "    # Calculate the exact Ritz value\n",
    "    exact_ritz = Exact_Ritz(np.array(test_data[i]))\n",
    "    exact_ritz_test.append(exact_ritz)\n",
    "    exact_ritz_bal = exact_ritz / ritz_dict_test[str(test_data[i])]\n",
    "\n",
    "    # Calculate the error\n",
    "    error = np.sqrt(abs((ritz - exact_ritz)/ritz_dict_test[str(test_data[i])]))\n",
    "    error_test.append(error)\n",
    "\n",
    "    # Calculate the relative error\n",
    "    rel_error = error / np.sqrt(abs(exact_ritz_bal))\n",
    "    rel_error_test.append(rel_error)\n",
    "    \n",
    "    # Calculate the relative error with the uniform grid\n",
    "    rel_error_uni = np.sqrt(abs( (ritz_dict_test[str(test_data[i])] - exact_ritz) / exact_ritz ))\n",
    "    rel_uniform_test.append(rel_error_uni)\n",
    "\n",
    "# Evaluate the NN in every training data and then compare the loss with the exact Ritz value\n",
    "\n",
    "# List to save the Ritz values\n",
    "ritz_train          = []\n",
    "exact_ritz_train    = []\n",
    "error_train         = []\n",
    "rel_error_train     = []\n",
    "rel_uniform_train   = []\n",
    "\n",
    "# Evaluate the NN in every training data\n",
    "for i in range(len(train_data)):\n",
    "    \n",
    "    # Calculate the Ritz value\n",
    "    ritz = solve_and_loss(forward_pass(np.array([train_data[i]]), trained_param), train_data[i])\n",
    "    ritz_train.append(ritz)\n",
    "    \n",
    "    # Calculate the exact Ritz value\n",
    "    exact_ritz = Exact_Ritz(np.array(train_data[i]))\n",
    "    exact_ritz_train.append(exact_ritz)\n",
    "    exact_ritz_bal = exact_ritz / ritz_dict_train[str(train_data[i])]\n",
    "\n",
    "    # Calculate the error\n",
    "    error = np.sqrt(abs((ritz - exact_ritz)/ritz_dict_train[str(train_data[i])]))\n",
    "    error_train.append(error)\n",
    "\n",
    "    # Calculate the relative error\n",
    "    rel_error = error / np.sqrt(abs(exact_ritz_bal))\n",
    "    rel_error_train.append(rel_error)\n",
    "\n",
    "    # Calculate the relative error with the uniform grid\n",
    "    rel_error_uni = np.sqrt(abs( (ritz_dict_train[str(train_data[i])] - exact_ritz) / exact_ritz ))\n",
    "    rel_uniform_train.append(rel_error_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics for the training set\n",
    "train_mean_abs_error = np.mean(error_train)\n",
    "train_mean_rel_error = np.mean(rel_error_train)\n",
    "train_std_abs_error = np.std(error_train)\n",
    "train_std_rel_error = np.std(rel_error_train)\n",
    "train_max_abs_error = np.max(error_train)\n",
    "train_max_rel_error = np.max(rel_error_train)\n",
    "train_uniform_mean_rel_error = np.mean(rel_uniform_train) \n",
    "train_uniform_max_rel_error = np.max(rel_uniform_train)\n",
    "\n",
    "# Compute statistics for the test set\n",
    "val_mean_abs_error = np.mean(error_test)\n",
    "val_mean_rel_error = np.mean(rel_error_test)\n",
    "val_std_abs_error = np.std(error_test)\n",
    "val_std_rel_error = np.std(rel_error_test)\n",
    "val_max_abs_error = np.max(error_test)\n",
    "val_max_rel_error = np.max(rel_error_test)\n",
    "val_uniform_mean_rel_error = np.mean(rel_uniform_test)\n",
    "val_uniform_max_rel_error = np.max(rel_uniform_test)\n",
    "\n",
    "# Create a DataFrame to summarize the errors\n",
    "data = {\n",
    "    'Set': ['Train', 'Test'],\n",
    "    'Mean Absolute Error': [train_mean_abs_error, val_mean_abs_error],\n",
    "    'Mean Relative Error': [train_mean_rel_error, val_mean_rel_error],\n",
    "    'Std Absolute Error': [train_std_abs_error, val_std_abs_error],\n",
    "    'Std Relative Error': [train_std_rel_error, val_std_rel_error],\n",
    "    'Max Absolute Error': [train_max_abs_error, val_max_abs_error],\n",
    "    'Max Relative Error': [train_max_rel_error, val_max_rel_error],\n",
    "    'Uniform grid Mean Relative error': [train_uniform_mean_rel_error, val_uniform_mean_rel_error],\n",
    "    'Uniform grid Max Relative error': [train_uniform_max_rel_error, val_uniform_max_rel_error]\n",
    "}\n",
    "\n",
    "df_errors = pd.DataFrame(data)\n",
    "df_errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
